"""
LoterIA - Pattern Analyzer (CORRIGIDO)
MÃ³dulo avanÃ§ado de anÃ¡lise de padrÃµes baseado no script original
Integra anÃ¡lise de divergÃªncia posicional, padrÃµes recorrentes e filtros condicionais
"""

import pandas as pd
import numpy as np
import sqlite3
from datetime import datetime
from itertools import combinations, product
from collections import Counter
from typing import Dict, List, Tuple, Optional
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PatternAnalyzer:
    """Analisador avanÃ§ado de padrÃµes para LoterIA"""
    
    def __init__(self, db_path: str = "data/loteria.db", use_sqlserver_data: bool = False, db_manager=None):
        self.db_path = db_path
        self.use_sqlserver_data = use_sqlserver_data
        self.db_manager = db_manager
        self.df_historico = None
        self.load_historical_data()
    
    def load_historical_data(self) -> None:
        """Carrega dados histÃ³ricos do banco"""
        try:
            if self.use_sqlserver_data and self.db_manager:
                # CORREÃ‡ÃƒO: Usar dados atualizados do SQL Server
                logger.info("ğŸ“Š Carregando dados do SQL Server para anÃ¡lise de padrÃµes...")
                conn = self.db_manager.connect()
                
                if self.db_manager.config.DB_TYPE.lower() == "sqlserver":
                    query = """
                    SELECT 
                        Concurso as concurso,
                        N1 as n1, N2 as n2, N3 as n3, N4 as n4, N5 as n5,
                        N6 as n6, N7 as n7, N8 as n8, N9 as n9, N10 as n10,
                        N11 as n11, N12 as n12, N13 as n13, N14 as n14, N15 as n15
                    FROM Resultados_INT 
                    ORDER BY Concurso ASC
                    """
                    self.df_historico = pd.read_sql_query(query, conn)
                    logger.info(f"âœ… Dados atualizados carregados: {len(self.df_historico)} concursos do SQL Server")
                else:
                    # Fallback para SQLite se SQL Server nÃ£o disponÃ­vel
                    self._load_from_sqlite()
            else:
                # MÃ©todo original: carregar do SQLite
                self._load_from_sqlite()
                
        except Exception as e:
            logger.error(f"âŒ Erro ao carregar dados: {e}")
            # Fallback para SQLite
            self._load_from_sqlite()
    
    def _load_from_sqlite(self) -> None:
        """MÃ©todo auxiliar para carregar do SQLite"""
        try:
            conn = sqlite3.connect(self.db_path)
            query = """
            SELECT * FROM resultados 
            ORDER BY concurso ASC
            """
            self.df_historico = pd.read_sql_query(query, conn)
            conn.close()
            logger.info(f"âœ… Dados histÃ³ricos carregados: {len(self.df_historico)} concursos")
        except Exception as e:
            logger.error(f"âŒ Erro ao carregar dados: {e}")
            raise
    
    def analisar_divergencia_posicional(self, janela_size: int = 15) -> pd.DataFrame:
        """
        AnÃ¡lise de divergÃªncia posicional - compara frequÃªncia histÃ³rica vs janela recente
          Args:
            janela_size: Tamanho da janela para anÃ¡lise recente
            
        Returns:
            DataFrame com anÃ¡lise de divergÃªncia por nÃºmero/posiÃ§Ã£o
        """
        logger.info(f"ğŸ” Iniciando anÃ¡lise de divergÃªncia posicional (janela: {janela_size})")
        
        df_total = self.df_historico.copy()
        df_janela = self.df_historico.tail(janela_size)
        
        posicoes = [f'n{i}' for i in range(1, 16)]  # Corrigido para minÃºsculas
        resultado = []
        
        for numero in range(1, 26):
            for pos in posicoes:
                # FrequÃªncia total histÃ³rica
                total_ocorrencias = (df_total[pos] == numero).sum()
                total_pct = total_ocorrencias / len(df_total) * 100
                
                # FrequÃªncia na janela recente
                janela_ocorrencias = (df_janela[pos] == numero).sum()
                janela_pct = janela_ocorrencias / len(df_janela) * 100
                
                # DivergÃªncia
                delta = janela_pct - total_pct
                status = self._avaliar_status_divergencia(delta)
                
                resultado.append({
                    'numero': numero,
                    'posicao': pos,
                    'freq_total_pct': round(total_pct, 2),
                    'freq_janela_pct': round(janela_pct, 2),
                    'divergencia_pct': round(delta, 2),
                    'status': status,
                    'peso_sugerido': self._calcular_peso_divergencia(janela_pct, status)
                })
        
        df_resultado = pd.DataFrame(resultado)
        
        # Log dos principais achados
        desvios_positivos = df_resultado[df_resultado['status'].isin(['ğŸ”¥ Muito acima', 'â¬†ï¸ Acima'])]
        desvios_negativos = df_resultado[df_resultado['status'].isin(['â„ï¸ Muito abaixo', 'â¬‡ï¸ Abaixo'])]
        
        logger.info(f"ğŸ“ˆ Desvios positivos encontrados: {len(desvios_positivos)}")
        logger.info(f"ğŸ“‰ Desvios negativos encontrados: {len(desvios_negativos)}")
        
        return df_resultado
    
    def _avaliar_status_divergencia(self, delta: float) -> str:
        """Avalia o status da divergÃªncia"""
        if delta > 15:
            return 'ğŸ”¥ Muito acima'
        elif delta > 5:
            return 'â¬†ï¸ Acima'
        elif delta < -15:
            return 'â„ï¸ Muito abaixo'
        elif delta < -5:
            return 'â¬‡ï¸ Abaixo'
        else:
            return 'âœ… EstÃ¡vel'
    
    def _calcular_peso_divergencia(self, freq_janela: float, status: str) -> float:
        """Calcula peso baseado na divergÃªncia"""
        pesos = {
            'ğŸ”¥ Muito acima': 0.1,
            'â¬†ï¸ Acima': 0.2,
            'âœ… EstÃ¡vel': 0.5,
            'â¬‡ï¸ Abaixo': 0.8,
            'â„ï¸ Muito abaixo': 1.0
        }
        return freq_janela * pesos.get(status, 0.5)
    
    def analisar_padrao_posicional_recorrente(self, padroes: Dict[str, int]) -> Dict:
        """
        AnÃ¡lise de padrÃµes posicionais recorrentes
        
        Args:
            padroes: DicionÃ¡rio com posiÃ§Ãµes e valores (ex: {'N1': 1, 'N15': 25})
            
        Returns:
            DicionÃ¡rio com anÃ¡lise do padrÃ£o
        """
        logger.info(f"ğŸ” Analisando padrÃ£o recorrente: {padroes}")
        
        # Localizar concursos que respeitam o padrÃ£o
        mask = self.df_historico.apply(
            lambda row: all(row.get(pos) == val for pos, val in padroes.items()), 
            axis=1
        )
        concursos_match = self.df_historico.loc[mask, 'concurso'].tolist()
        
        if not concursos_match:
            logger.warning("âš ï¸ Nenhum concurso encontrado com o padrÃ£o informado")
            return None
        
        # Calcular estatÃ­sticas
        distancias = np.diff(concursos_match)
        media_dist = np.mean(distancias) if len(distancias) > 0 else 0
        mediana_dist = np.median(distancias) if len(distancias) > 0 else 0
        
        # Dados atuais
        concurso_atual = self.df_historico['concurso'].max()
        ultima_ocorrencia = concursos_match[-1]
        dist_atual = concurso_atual - ultima_ocorrencia
        
        # Alerta sazonal
        alerta = media_dist > 0 and dist_atual >= (media_dist * 0.9)
        
        # PrevisÃ£o
        concurso_previsto = int(ultima_ocorrencia + media_dist) if media_dist > 0 else ultima_ocorrencia
        margem = max(1, int(media_dist * 0.1))
        
        # EstatÃ­sticas dos concursos com padrÃ£o
        estatisticas_cols = ['soma_total', 'qtde_pares', 'qtde_impares']
        # Adicionar colunas se existirem
        available_cols = [col for col in estatisticas_cols if col in self.df_historico.columns]
        
        if available_cols:
            estatisticas = self.df_historico[
                self.df_historico['concurso'].isin(concursos_match)
            ][available_cols].mean()
        else:
            estatisticas = pd.Series()
        
        resultado = {
            'concursos_ocorrencia': concursos_match,
            'total_ocorrencias': len(concursos_match),
            'distancias': distancias.tolist(),
            'media_distancia': media_dist,
            'mediana_distancia': mediana_dist,
            'ultima_ocorrencia': ultima_ocorrencia,
            'concurso_atual': concurso_atual,
            'distancia_atual': dist_atual,
            'alerta_sazonal': alerta,
            'concurso_previsto': concurso_previsto,
            'margem_erro': margem,
            'padrao': list(padroes.values()),
            'estatisticas_medias': estatisticas.to_dict() if not estatisticas.empty else {}
        }
        
        logger.info(f"ğŸ“Š PadrÃ£o encontrado em {len(concursos_match)} concursos")
        logger.info(f"ğŸ“… Ãšltima ocorrÃªncia: {ultima_ocorrencia}, PrevisÃ£o: {concurso_previsto} Â± {margem}")
        
        if alerta:
            logger.warning("ğŸš¨ ALERTA: PadrÃ£o prÃ³ximo de se repetir!")
        
        return resultado
    
    def diagnostico_filtros_condicionais(self, 
                                       coluna_filtro: str,
                                       valores_filtro: List[int],
                                       colunas_analise: List[str]) -> pd.DataFrame:
        """
        DiagnÃ³stico de filtros condicionais - analisa estatÃ­sticas baseadas em filtro fixo
        
        Args:
            coluna_filtro: Nome da coluna para filtro
            valores_filtro: Lista de valores para filtrar
            colunas_analise: Colunas para anÃ¡lise estatÃ­stica
            
        Returns:
            DataFrame com estatÃ­sticas condicionais
        """
        logger.info(f"ğŸ¯ DiagnÃ³stico condicional: {coluna_filtro} in {valores_filtro}")
        
        # Filtrar dados
        df_filtrado = self.df_historico[
            self.df_historico[coluna_filtro].isin(valores_filtro)
        ]
        
        if df_filtrado.empty:
            logger.warning(f"âš ï¸ Nenhum registro encontrado para filtro {coluna_filtro} in {valores_filtro}")
            return pd.DataFrame()
        
        # Calcular estatÃ­sticas apenas para colunas existentes
        colunas_disponiveis = [col for col in colunas_analise if col in df_filtrado.columns]
        
        if not colunas_disponiveis:
            logger.warning(f"âš ï¸ Nenhuma coluna de anÃ¡lise disponÃ­vel: {colunas_analise}")
            return pd.DataFrame()
        
        estatisticas = df_filtrado[colunas_disponiveis].describe().T
        
        # Adicionar moda
        try:
            modas = df_filtrado[colunas_disponiveis].mode()
            if not modas.empty:
                estatisticas['moda'] = modas.iloc[0]
        except Exception as e:
            logger.warning(f"âš ï¸ Erro ao calcular moda: {e}")
        
        logger.info(f"ğŸ“Š AnÃ¡lise baseada em {len(df_filtrado)} concursos")
        
        return estatisticas
    
    def analisar_frequencia_temporal(self, frame_size: int = 15) -> pd.DataFrame:
        """
        AnÃ¡lise de frequÃªncia temporal - compara duas janelas de tempo
        
        Args:
            frame_size: Tamanho de cada janela
            
        Returns:
            DataFrame com anÃ¡lise de tendÃªncia
        """
        logger.info(f"ğŸ“ˆ Analisando tendÃªncia temporal (janelas de {frame_size})")
        
        if len(self.df_historico) < frame_size * 2:
            logger.error(f"âŒ Dados insuficientes. NecessÃ¡rio: {frame_size * 2}, DisponÃ­vel: {len(self.df_historico)}")
            return pd.DataFrame()
        
        # Separar janelas
        df_passado = self.df_historico.tail(frame_size * 2).head(frame_size)
        df_atual = self.df_historico.tail(frame_size)
        
        def contar_frequencias(df_window):
            freq = {}
            posicoes = [f'n{i}' for i in range(1, 16)]  # Corrigido para minÃºsculas
            for col in posicoes:
                if col in df_window.columns:
                    for val in df_window[col].values:
                        freq[val] = freq.get(val, 0) + 1
            return freq
        
        freq_passado = contar_frequencias(df_passado)
        freq_atual = contar_frequencias(df_atual)
        
        # Construir resultado
        dados = []
        for numero in range(1, 26):
            atual = freq_atual.get(numero, 0)
            passado = freq_passado.get(numero, 0)
            media_atual = atual / frame_size if frame_size > 0 else 0
            media_passada = passado / frame_size if frame_size > 0 else 0
            diferenca = atual - passado
            
            # Classificar tendÃªncia
            if diferenca > 2:
                tendencia = 'ğŸ”¥ Forte alta'
            elif diferenca > 0:
                tendencia = 'â¬†ï¸ Alta'
            elif diferenca < -2:
                tendencia = 'â„ï¸ Forte baixa'
            elif diferenca < 0:
                tendencia = 'â¬‡ï¸ Baixa'
            else:
                tendencia = 'âœ… EstÃ¡vel'
            
            dados.append({
                'numero': numero,
                'freq_atual': atual,
                'freq_passada': passado,
                'media_atual_pct': f'{media_atual:.1%}',
                'media_passada_pct': f'{media_passada:.1%}',
                'diferenca': diferenca,
                'tendencia': tendencia
            })
        
        df_resultado = pd.DataFrame(dados)
        df_resultado = df_resultado.sort_values(by='diferenca', ascending=False).reset_index(drop=True)
        
        # Log das principais tendÃªncias
        altas = df_resultado[df_resultado['tendencia'].isin(['ğŸ”¥ Forte alta', 'â¬†ï¸ Alta'])]
        baixas = df_resultado[df_resultado['tendencia'].isin(['â„ï¸ Forte baixa', 'â¬‡ï¸ Baixa'])]
        
        logger.info(f"ğŸ“ˆ NÃºmeros em alta: {len(altas)}")
        logger.info(f"ğŸ“‰ NÃºmeros em baixa: {len(baixas)}")
        
        return df_resultado
    
    def gerar_combinacoes_inteligentes(self, 
                                     df_divergencia: pd.DataFrame,
                                     limite_combinacoes: int = 10,
                                     usar_pesos: bool = True) -> pd.DataFrame:
        """
        Gera combinaÃ§Ãµes baseadas na anÃ¡lise de divergÃªncia posicional
        
        Args:
            df_divergencia: DataFrame da anÃ¡lise de divergÃªncia
            limite_combinacoes: NÃºmero mÃ¡ximo de combinaÃ§Ãµes
            usar_pesos: Se deve usar sistema de pesos
            
        Returns:
            DataFrame com combinaÃ§Ãµes geradas
        """
        logger.info(f"ğŸ¯ Gerando {limite_combinacoes} combinaÃ§Ãµes inteligentes")
        
        posicoes = [f'n{i}' for i in range(1, 16)]  # Corrigido para minÃºsculas
        
        # Mapear pesos por posiÃ§Ã£o
        mapa_pesos = {pos: {} for pos in posicoes}
        
        for _, row in df_divergencia.iterrows():
            numero = int(row['numero'])
            posicao = row['posicao']
            peso = row['peso_sugerido'] if usar_pesos else 1.0
            
            if posicao in mapa_pesos:
                mapa_pesos[posicao][numero] = peso
        
        # Selecionar candidatos por posiÃ§Ã£o (top 3)
        candidatos_por_posicao = {}
        for pos in posicoes:
            if pos in mapa_pesos and mapa_pesos[pos]:
                candidatos = sorted(
                    mapa_pesos[pos].items(), 
                    key=lambda x: x[1], 
                    reverse=True
                )[:3]
                candidatos_por_posicao[pos] = [num for num, peso in candidatos]
            else:
                # Fallback para nÃºmeros mais comuns
                candidatos_por_posicao[pos] = list(range(1, 26))[:3]
        
        # Gerar combinaÃ§Ãµes
        possibilidades = [candidatos_por_posicao[pos] for pos in posicoes]
        combinacoes_cruas = list(product(*possibilidades))
        
        # Filtrar combinaÃ§Ãµes vÃ¡lidas (15 nÃºmeros Ãºnicos)
        combinacoes_unicas = []
        for comb in combinacoes_cruas:
            numeros_unicos = sorted(set(comb))
            if len(numeros_unicos) == 15:
                combinacoes_unicas.append(numeros_unicos)
        
        # Limitar e pontuar
        combinacoes_unicas = list(set(tuple(c) for c in combinacoes_unicas))
        
        if usar_pesos:
            def pontuar(comb):
                score = 0
                for i, num in enumerate(comb):
                    pos = f'N{i+1}'
                    if pos in mapa_pesos and num in mapa_pesos[pos]:
                        score += mapa_pesos[pos][num]
                return score
            
            combinacoes_unicas = sorted(
                combinacoes_unicas, 
                key=pontuar, 
                reverse=True
            )
        
        # Limitar resultado
        combinacoes_finais = combinacoes_unicas[:limite_combinacoes]
        
        # Criar DataFrame
        df_resultado = pd.DataFrame(
            combinacoes_finais, 
            columns=posicoes
        )
        
        # Adicionar metadados
        df_resultado['data_geracao'] = datetime.now()
        df_resultado['metodo'] = 'divergencia_posicional'
        
        logger.info(f"âœ… {len(df_resultado)} combinaÃ§Ãµes geradas com sucesso")
        
        return df_resultado
    
    def salvar_analise(self, 
                      df_resultado: pd.DataFrame, 
                      nome_tabela: str = "analise_padroes") -> None:
        """Salva resultado da anÃ¡lise no banco"""
        try:
            conn = sqlite3.connect(self.db_path)
            df_resultado.to_sql(nome_tabela, conn, if_exists='replace', index=False)
            conn.close()
            logger.info(f"âœ… AnÃ¡lise salva na tabela {nome_tabela}")
        except Exception as e:
            logger.error(f"âŒ Erro ao salvar anÃ¡lise: {e}")
            raise

if __name__ == "__main__":
    # Exemplo de uso
    analyzer = PatternAnalyzer()
    
    # 1. AnÃ¡lise de divergÃªncia posicional
    print("ğŸ” Executando anÃ¡lise de divergÃªncia posicional...")
    df_divergencia = analyzer.analisar_divergencia_posicional(janela_size=15)
    print(df_divergencia.head(10))
    
    # 2. AnÃ¡lise de padrÃ£o recorrente
    print("\nğŸ” Executando anÃ¡lise de padrÃ£o recorrente...")
    padrao_exemplo = {'N1': 1, 'N15': 25}
    resultado_padrao = analyzer.analisar_padrao_posicional_recorrente(padrao_exemplo)
    if resultado_padrao:
        print(f"PadrÃ£o encontrado em {resultado_padrao['total_ocorrencias']} concursos")
    
    # 3. Gerar combinaÃ§Ãµes inteligentes
    print("\nğŸ¯ Gerando combinaÃ§Ãµes inteligentes...")
    df_combinacoes = analyzer.gerar_combinacoes_inteligentes(
        df_divergencia, 
        limite_combinacoes=5
    )
    print(df_combinacoes)
