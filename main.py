#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LoterIA v3.0 - Sistema AVAN√áADO de Predi√ß√£o de Loteria com An√°lise de Padr√µes
Vers√£o 3.0.0 - Integra√ß√£o com Pattern Analyzer e T√©cnicas Avan√ßadas
Desenvolvido com TensorFlow + An√°lise de Padr√µes Inteligente
"""

import os
import sys
import numpy as np
import pandas as pd
import sqlite3
import pyodbc
import logging
from datetime import datetime
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass
from collections import Counter

# Configurar TensorFlow para compatibilidade
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Importar nosso analisador de padr√µes
from pattern_analyzer import PatternAnalyzer

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class LoterIAConfig:
    """Configura√ß√µes globais do sistema"""
    DB_TYPE: str = "sqlserver"  # sqlserver ou sqlite - CORRIGIDO: usando SQL Server
    SQL_SERVER: str = "DESKTOP-K6JPBDS"
    SQL_DATABASE: str = "LOTOFACIL"
    SQL_DRIVER: str = "ODBC Driver 17 for SQL Server"
    SQLITE_PATH: str = "data/loteria.db"
    
    # Configura√ß√µes do modelo
    MODEL_PATH: str = "models/loteria_model_v3.h5"
    RESULTS_PATH: str = "results/"
    
    # Par√¢metros de treinamento
    EPOCHS: int = 100
    BATCH_SIZE: int = 32
    VALIDATION_SPLIT: float = 0.2

class DatabaseManager:
    """Gerenciador de conex√£o com banco de dados"""
    
    def __init__(self, config: LoterIAConfig):
        self.config = config
        self.connection = None
    
    def connect(self):
        """Estabelece conex√£o com o banco"""
        try:
            if self.config.DB_TYPE.lower() == "sqlserver":
                connection_string = (
                    f"DRIVER={{{self.config.SQL_DRIVER}}};"
                    f"SERVER={self.config.SQL_SERVER};"
                    f"DATABASE={self.config.SQL_DATABASE};"
                    f"Trusted_Connection=yes;"
                )
                self.connection = pyodbc.connect(connection_string)
            else:
                self.connection = sqlite3.connect(self.config.SQLITE_PATH)
            
            logger.info("‚úÖ Conex√£o com banco estabelecida")
            return self.connection
            
        except Exception as e:
            logger.error(f"‚ùå Erro de conex√£o: {e}")
            return None
    
    def close(self):
        """Fecha conex√£o com banco"""
        if self.connection:
            self.connection.close()
            logger.info("üîå Conex√£o com banco fechada")

class DataProcessor:
    """Processador de dados com recursos avan√ßados"""
    
    def __init__(self, config: LoterIAConfig):
        self.config = config
        self.db_manager = DatabaseManager(config)
        self.scaler = StandardScaler()
    
    def load_data(self) -> pd.DataFrame:
        """Carrega dados hist√≥ricos"""
        try:
            conn = self.db_manager.connect()
            if self.db_manager.config.DB_TYPE.lower() == "sqlserver":
                # Query para SQL Server com tabela Resultados_INT
                query = """
                SELECT 
                    Concurso, data_sorteio,
                    N1, N2, N3, N4, N5, N6, N7, N8, N9, N10, N11, N12, N13, N14, N15,
                    QtdePrimos, QtdeFibonacci, QtdeImpares, SomaTotal,
                    Quintil1, Quintil2, Quintil3, Quintil4, Quintil5,
                    QtdeGaps, QtdeRepetidos, SEQ, DistanciaExtremos,
                    ParesSequencia, QtdeMultiplos3, ParesSaltados,
                    Faixa_Baixa, Faixa_Media, Faixa_Alta, RepetidosMesmaPosicao
                FROM Resultados_INT 
                ORDER BY Concurso ASC
                """
            else:
                # Query para SQLite (fallback)
                query = """
                SELECT * FROM resultados 
                ORDER BY concurso ASC
                """
            
            df = pd.read_sql_query(query, conn)
            logger.info(f"üìä Dados carregados: {len(df)} registros")
            
            # Normalizar nomes das colunas
            if self.db_manager.config.DB_TYPE.lower() == "sqlserver":
                df = df.rename(columns={'Concurso': 'concurso'})
                # Converter N1-N15 para n1-n15 para compatibilidade com PatternAnalyzer
                rename_dict = {f'N{i}': f'n{i}' for i in range(1, 16)}
                df = df.rename(columns=rename_dict)
            
            return df
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar dados: {e}")
            raise
        finally:
            self.db_manager.close()
    
    def extract_features_enhanced(self, df: pd.DataFrame) -> np.ndarray:
        """Extrai features avan√ßadas incluindo an√°lise de padr√µes"""
        logger.info("üîß Extraindo features avan√ßadas...")
        
        features = []
        
        for _, row in df.iterrows():
            # Acessar colunas n1-n15 (min√∫sculas - ap√≥s normaliza√ß√£o)
            numeros = [row[f'n{i}'] for i in range(1, 16)]
            numeros = sorted(numeros)
            
            # Features b√°sicas
            feature_row = []
            
            # 1. N√∫meros individuais (15 features)
            feature_row.extend(numeros)
            
            # 2. Features estat√≠sticas b√°sicas
            feature_row.append(sum(numeros))  # Soma total
            feature_row.append(np.mean(numeros))  # M√©dia
            feature_row.append(np.std(numeros))  # Desvio padr√£o
            feature_row.append(max(numeros) - min(numeros))  # Range
            
            # 3. Features de padr√£o
            pares = sum(1 for n in numeros if n % 2 == 0)
            impares = 15 - pares
            feature_row.extend([pares, impares])
            
            # 4. Features de distribui√ß√£o por dezenas
            dezena1 = sum(1 for n in numeros if 1 <= n <= 5)
            dezena2 = sum(1 for n in numeros if 6 <= n <= 10)
            dezena3 = sum(1 for n in numeros if 11 <= n <= 15)
            dezena4 = sum(1 for n in numeros if 16 <= n <= 20)
            dezena5 = sum(1 for n in numeros if 21 <= n <= 25)
            feature_row.extend([dezena1, dezena2, dezena3, dezena4, dezena5])
            
            # 5. Features de sequ√™ncia
            gaps = [numeros[i+1] - numeros[i] for i in range(14)]
            feature_row.append(np.mean(gaps))  # Gap m√©dio
            feature_row.append(max(gaps))  # Gap m√°ximo
            feature_row.append(sum(1 for g in gaps if g == 1))  # Sequ√™ncias consecutivas
            
            # 6. Features de n√∫meros primos
            primos = [2, 3, 5, 7, 11, 13, 17, 19, 23]
            qtd_primos = sum(1 for n in numeros if n in primos)
            feature_row.append(qtd_primos)
            
            # 7. Features de Fibonacci
            fibonacci = [1, 2, 3, 5, 8, 13, 21]
            qtd_fibonacci = sum(1 for n in numeros if n in fibonacci)
            feature_row.append(qtd_fibonacci)
            
            # 8. Features temporais (posi√ß√£o relativa no hist√≥rico)
            feature_row.append(row['concurso'] / df['concurso'].max())
            
            features.append(feature_row)
        
        features_array = np.array(features, dtype=np.float32)
        
        # Normalizar features
        features_normalized = self.scaler.fit_transform(features_array)
        
        logger.info(f"‚úÖ Features extra√≠das: shape {features_normalized.shape}")
        return features_normalized
    
    def create_sequences(self, features: np.ndarray, sequence_length: int = 10) -> Tuple[np.ndarray, np.ndarray]:
        """Cria sequ√™ncias temporais para treinamento"""
        logger.info(f"üîÑ Criando sequ√™ncias temporais (length={sequence_length})")
        
        X, y = [], []
        
        for i in range(sequence_length, len(features)):
            X.append(features[i-sequence_length:i])
            y.append(features[i][:15])  # Apenas os 15 n√∫meros
        
        X = np.array(X, dtype=np.float32)
        y = np.array(y, dtype=np.float32)
        
        logger.info(f"‚úÖ Sequ√™ncias criadas: X{X.shape}, y{y.shape}")
        return X, y

class LoterIAModelV3:
    """Modelo neural avan√ßado para LoterIA v3.0"""
    
    def __init__(self, config: LoterIAConfig):
        self.config = config
        self.model = None
        
    def build_model(self, input_shape: Tuple[int, int]) -> keras.Model:
        """Constr√≥i modelo neural avan√ßado"""
        logger.info(f"üèóÔ∏è Construindo modelo neural v3.0 com input_shape: {input_shape}")
        
        model = keras.Sequential([
            # Camada de entrada LSTM para sequ√™ncias temporais
            keras.layers.LSTM(128, return_sequences=True, input_shape=input_shape),
            keras.layers.Dropout(0.2),
            keras.layers.BatchNormalization(),
            
            # Segunda camada LSTM
            keras.layers.LSTM(64, return_sequences=False),
            keras.layers.Dropout(0.2),
            keras.layers.BatchNormalization(),
            
            # Camadas densas para processamento final
            keras.layers.Dense(128, activation='relu'),
            keras.layers.Dropout(0.3),
            keras.layers.BatchNormalization(),
            
            keras.layers.Dense(64, activation='relu'),
            keras.layers.Dropout(0.2),
            
            keras.layers.Dense(32, activation='relu'),
            keras.layers.Dropout(0.1),
            
            # Camada de sa√≠da para 15 n√∫meros (0-1 normalizado)
            keras.layers.Dense(15, activation='sigmoid')
        ])
          # Compilar modelo
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='mean_squared_error',
            metrics=['mean_absolute_error']
        )
        
        self.model = model
        logger.info("‚úÖ Modelo constru√≠do com sucesso")
        return model
    
    def train(self, X_train: np.ndarray, y_train: np.ndarray) -> Dict:
        """Treina o modelo"""
        logger.info("üöÄ Iniciando treinamento do modelo neural...")
        
        # Callbacks para melhor treinamento
        callbacks = [
            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
            keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5, min_lr=0.00001),
            keras.callbacks.ModelCheckpoint(self.config.MODEL_PATH, save_best_only=True)
        ]
        
        # Treinar modelo
        history = self.model.fit(
            X_train, y_train,
            epochs=self.config.EPOCHS,
            batch_size=self.config.BATCH_SIZE,
            validation_split=self.config.VALIDATION_SPLIT,
            callbacks=callbacks,
            verbose=1
        )
        
        # Salvar modelo
        self.model.save(self.config.MODEL_PATH)
        logger.info(f"üíæ Modelo salvo em: {self.config.MODEL_PATH}")
        
        return history.history
    
    def load_model(self) -> bool:
        """Carrega modelo treinado"""
        try:
            if os.path.exists(self.config.MODEL_PATH):
                self.model = keras.models.load_model(self.config.MODEL_PATH)
                logger.info(f"‚úÖ Modelo carregado: {self.config.MODEL_PATH}")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è Arquivo de modelo n√£o encontrado: {self.config.MODEL_PATH}")
                return False
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar modelo: {e}")
            return False

class LoterIAPredictorV3:
    """Sistema de predi√ß√£o avan√ßado v3.0 com an√°lise de padr√µes"""
    
    def __init__(self, config: LoterIAConfig):
        self.config = config
        self.data_processor = DataProcessor(config)
        self.model = LoterIAModelV3(config)
        self.pattern_analyzer = PatternAnalyzer(use_sqlserver_data=True, db_manager=DatabaseManager(config))
    
    def train_complete_system(self) -> Dict:
        """Treina o sistema completo"""
        logger.info("üéØ Iniciando processo de treinamento completo...")
        
        # 1. Carregar dados
        df = self.data_processor.load_data()
        
        # 2. Extrair features
        features = self.data_processor.extract_features_enhanced(df)
        
        # 3. Criar sequ√™ncias temporais
        X, y = self.data_processor.create_sequences(features)
        
        # 4. Construir modelo
        model = self.model.build_model(input_shape=(X.shape[1], X.shape[2]))
        
        # 5. Treinar modelo
        history = self.model.train(X, y)
        
        logger.info("üéâ Treinamento completo finalizado!")
        return history
    
    def predict_next_draw(self, num_predictions: int = 5) -> List[Dict]:
        """Gera predi√ß√µes inteligentes combinando IA + an√°lise de padr√µes"""
        logger.info(f"üîÆ Gerando {num_predictions} predi√ß√µes inteligentes...")
        
        # 1. Carregar dados atuais
        df = self.data_processor.load_data()
        
        # 2. Executar an√°lises de padr√µes
        logger.info("üîç Executando an√°lise de padr√µes...")
        df_divergencia = self.pattern_analyzer.analisar_divergencia_posicional(janela_size=15)
        df_frequencia = self.pattern_analyzer.analisar_frequencia_temporal(frame_size=15)
        
        # 3. Gerar predi√ß√µes da IA
        logger.info("ü§ñ Gerando predi√ß√µes com IA...")
        ai_predictions = self._generate_ai_predictions(df, num_predictions)
        
        # 4. Gerar combina√ß√µes baseadas em padr√µes
        logger.info("üéØ Gerando combina√ß√µes baseadas em padr√µes...")
        df_combinacoes_padroes = self.pattern_analyzer.gerar_combinacoes_inteligentes(
            df_divergencia=df_divergencia,
            limite_combinacoes=num_predictions,
            usar_pesos=True
        )
        
        # 5. Combinar resultados
        predicoes = []
        
        for i in range(num_predictions):
            predicao = {
                'id': i + 1,
                'numeros': [],
                'metodo': 'H√≠brido',
                'confianca': 0.5,
                'timestamp': datetime.now()
            }
            
            # Priorizar predi√ß√µes da IA se dispon√≠veis
            if i < len(ai_predictions):
                predicao['numeros'] = ai_predictions[i]
                predicao['metodo'] = 'IA Neural'
                predicao['confianca'] = 0.7
            
            # Usar an√°lise de padr√µes como fallback ou complemento
            elif i < len(df_combinacoes_padroes):
                pattern_nums = df_combinacoes_padroes.iloc[i][[f'n{j}' for j in range(1, 16)]].values
                predicao['numeros'] = sorted(pattern_nums)
                predicao['metodo'] = 'An√°lise de Padr√µes'
                predicao['confianca'] = 0.6
            
            # Garantir 15 n√∫meros √∫nicos
            while len(predicao['numeros']) < 15:
                num_aleatorio = np.random.randint(1, 26)
                if num_aleatorio not in predicao['numeros']:
                    predicao['numeros'].append(num_aleatorio)
            
            predicao['numeros'] = sorted(predicao['numeros'][:15])
            
            # Adicionar m√©tricas de an√°lise
            self._add_analysis_metrics(predicao, df_frequencia, df_divergencia)
            
            predicoes.append(predicao)
        
        return predicoes
    
    def _generate_ai_predictions(self, df: pd.DataFrame, num_predictions: int) -> List[List[int]]:
        """Gera predi√ß√µes usando IA neural"""
        if not self.model.load_model():
            logger.warning("‚ö†Ô∏è Modelo n√£o carregado, usando predi√ß√µes aleat√≥rias")
            return []
        
        try:            # Recompilar modelo com configura√ß√µes atuais
            self.model.model.compile(
                optimizer=keras.optimizers.Adam(learning_rate=0.001),
                loss='mean_squared_error',
                metrics=['mean_absolute_error']
            )
            logger.info("üîÑ Modelo recompilado com configura√ß√µes atuais")
            
            # Preparar dados para predi√ß√£o
            features = self.data_processor.extract_features_enhanced(df)
            
            # Usar √∫ltimas sequ√™ncias para predi√ß√£o
            sequence_length = 10
            if len(features) >= sequence_length:
                last_sequence = features[-sequence_length:].reshape(1, sequence_length, -1)
                
                predictions = []
                for _ in range(num_predictions):
                    # Predi√ß√£o neural
                    pred = self.model.model.predict(last_sequence, verbose=0)[0]
                    
                    # Converter predi√ß√£o para n√∫meros de 1-25
                    pred_numbers = (pred * 25 + 1).astype(int)
                    pred_numbers = np.clip(pred_numbers, 1, 25)
                    
                    # Garantir 15 n√∫meros √∫nicos
                    unique_numbers = []
                    for num in pred_numbers:
                        if num not in unique_numbers and len(unique_numbers) < 15:
                            unique_numbers.append(int(num))
                    
                    # Completar se necess√°rio
                    while len(unique_numbers) < 15:
                        num = np.random.randint(1, 26)
                        if num not in unique_numbers:
                            unique_numbers.append(num)
                    
                    predictions.append(sorted(unique_numbers[:15]))
                    
                    # Adicionar ru√≠do para pr√≥xima predi√ß√£o
                    last_sequence = last_sequence + np.random.normal(0, 0.01, last_sequence.shape)
                
                logger.info("‚úÖ Predi√ß√µes IA geradas com sucesso")
                return predictions
            
        except Exception as e:
            logger.error(f"‚ùå Erro na predi√ß√£o IA: {e}")
        
        return []
    
    def _add_analysis_metrics(self, predicao: Dict, 
                            df_frequencia: pd.DataFrame, 
                            df_divergencia: pd.DataFrame) -> None:
        """Adiciona m√©tricas de an√°lise √† predi√ß√£o"""
        numeros = predicao['numeros']
        
        # An√°lise de tend√™ncia
        tendencias = []
        for num in numeros:
            freq_info = df_frequencia[df_frequencia['numero'] == num]
            if not freq_info.empty:
                tendencias.append(freq_info.iloc[0]['tendencia'])
        
        # An√°lise de diverg√™ncia
        divergencias = []
        for num in numeros:
            div_info = df_divergencia[df_divergencia['numero'] == num]
            if not div_info.empty:
                divergencias.append(div_info.iloc[0]['status'])
        
        # Estat√≠sticas
        predicao['estatisticas'] = {
            'soma_total': sum(numeros),
            'media': np.mean(numeros),
            'pares': sum(1 for n in numeros if n % 2 == 0),
            'impares': sum(1 for n in numeros if n % 2 == 1),
            'tendencias': Counter(tendencias).most_common(),
            'status_divergencia': Counter(divergencias).most_common()
        }
    
    def save_predictions(self, predicoes: List[Dict], filename: str = None) -> str:
        """Salva predi√ß√µes em arquivo"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"predicao_v3_{timestamp}.txt"
        
        filepath = os.path.join(self.config.RESULTS_PATH, filename)
        
        # Criar diret√≥rio se n√£o existir
        os.makedirs(self.config.RESULTS_PATH, exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("üé≤ LoterIA v3.0 - Predi√ß√µes Inteligentes\n")
            f.write("=" * 50 + "\n")
            f.write(f"Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
            f.write(f"Total de predi√ß√µes: {len(predicoes)}\n\n")
            
            for i, pred in enumerate(predicoes, 1):
                f.write(f"PREDI√á√ÉO {i} ({pred['metodo']}) - Confian√ßa: {pred['confianca']:.1%}\n")
                f.write("-" * 30 + "\n")
                
                # N√∫meros formatados
                numeros_str = " - ".join(f"{n:02d}" for n in pred['numeros'])
                f.write(f"N√∫meros: {numeros_str}\n")
                
                # Estat√≠sticas
                stats = pred.get('estatisticas', {})
                f.write(f"Soma: {stats.get('soma_total', 0)}\n")
                f.write(f"Pares/√çmpares: {stats.get('pares', 0)}/{stats.get('impares', 0)}\n")
                  # Tend√™ncias principais
                tendencias = stats.get('tendencias', [])
                if tendencias:
                    f.write(f"Tend√™ncias: {', '.join([f'{t[0]} ({t[1]})' for t in tendencias[:3]])}\n")
                
                f.write("\n")
        
        logger.info(f"üíæ Predi√ß√µes salvas em: {filepath}")
        return filepath

def exibir_banner():
    """Exibe banner do sistema"""
    print("üé≤ LoterIA v3.0 - Sistema Avan√ßado de Predi√ß√£o de Loteria")
    print("=" * 60)

def exibir_menu():
    """Exibe menu principal"""
    print("\nüìã MENU PRINCIPAL:")
    print("1. üöÄ Treinar Modelo")
    print("2. üîÆ Gerar Predi√ß√µes")
    print("3. üîç An√°lise de Padr√µes")
    print("4. üìä An√°lise de Diverg√™ncia")
    print("5. üìà An√°lise de Frequ√™ncia Temporal")
    print("0. ‚ùå Sair")

def main():
    """Fun√ß√£o principal"""
    config = LoterIAConfig()
    predictor = LoterIAPredictorV3(config)
    
    exibir_banner()
    
    while True:
        try:
            exibir_menu()
            opcao = input("üëâ Escolha uma op√ß√£o: ").strip()
            
            if opcao == "0":
                print("üëã Encerrando LoterIA v3.0...")
                break
                
            elif opcao == "1":
                print("üöÄ Iniciando treinamento do modelo...")
                try:
                    history = predictor.train_complete_system()
                    print("‚úÖ Treinamento conclu√≠do com sucesso!")
                except Exception as e:
                    logger.error(f"‚ùå Erro no treinamento: {e}")
                    print(f"‚ùå Erro: {e}")
                
            elif opcao == "2":
                try:
                    num_pred = int(input("Quantas predi√ß√µes gerar? (1-10): "))
                    if 1 <= num_pred <= 10:
                        predicoes = predictor.predict_next_draw(num_pred)
                        
                        # Exibir predi√ß√µes
                        print(f"\nüéØ {len(predicoes)} PREDI√á√ïES GERADAS:")
                        print("=" * 50)
                        
                        for pred in predicoes:
                            numeros = " - ".join(f"{n:02d}" for n in pred['numeros'])
                            print(f"üé≤ {pred['metodo']} (Confian√ßa: {pred['confianca']:.1%}): {numeros}")
                        
                        # Salvar em arquivo
                        arquivo = predictor.save_predictions(predicoes)
                        print(f"üíæ Resultados salvos em: {arquivo}")
                        
                    else:
                        print("‚ö†Ô∏è N√∫mero deve estar entre 1 e 10")
                        
                except ValueError:
                    print("‚ö†Ô∏è Entrada inv√°lida")
                except Exception as e:
                    logger.error(f"‚ùå Erro fatal: {e}")
                    print(f"‚ùå Erro: {e}")
            
            elif opcao == "3":
                print("üîç Executando an√°lise de padr√µes...")
                try:
                    # An√°lise de diverg√™ncia
                    df_div = predictor.pattern_analyzer.analisar_divergencia_posicional(15)
                    print(f"\nüìä An√°lise de diverg√™ncia: {len(df_div)} registros")
                    
                    # Mostrar principais desvios positivos
                    print("\nüî• TOP 5 DESVIOS POSITIVOS:")
                    positivos = df_div[df_div['divergencia_pct'] > 0].nlargest(5, 'divergencia_pct')
                    for _, row in positivos.iterrows():
                        print(f"  N¬∫ {row['numero']:02d} na {row['posicao']}: +{row['divergencia_pct']:.1f}% {row['status']}")
                    
                    # Mostrar principais desvios negativos
                    print("\n‚ùÑÔ∏è TOP 5 DESVIOS NEGATIVOS:")
                    negativos = df_div[df_div['divergencia_pct'] < 0].nsmallest(5, 'divergencia_pct')
                    for _, row in negativos.iterrows():
                        print(f"  N¬∫ {row['numero']:02d} na {row['posicao']}: {row['divergencia_pct']:.1f}% {row['status']}")
                        
                except Exception as e:
                    logger.error(f"‚ùå Erro na an√°lise: {e}")
                    print(f"‚ùå Erro: {e}")
            
            elif opcao == "4":
                print("üìä Executando an√°lise de diverg√™ncia detalhada...")
                try:
                    janela = int(input("Tamanho da janela (padr√£o 15): ") or 15)
                    df_div = predictor.pattern_analyzer.analisar_divergencia_posicional(janela)
                    
                    # Mostrar principais desvios
                    print("\nüî• MAIORES DESVIOS POSITIVOS:")
                    positivos = df_div[df_div['status'].isin(['üî• Muito acima', '‚¨ÜÔ∏è Acima'])]
                    print(positivos.nlargest(10, 'divergencia_pct')[
                        ['numero', 'posicao', 'divergencia_pct', 'status']
                    ].to_string(index=False))
                    
                    print("\n‚ùÑÔ∏è MAIORES DESVIOS NEGATIVOS:")
                    negativos = df_div[df_div['status'].isin(['‚ùÑÔ∏è Muito abaixo', '‚¨áÔ∏è Abaixo'])]
                    print(negativos.nsmallest(10, 'divergencia_pct')[
                        ['numero', 'posicao', 'divergencia_pct', 'status']
                    ].to_string(index=False))
                    
                except ValueError:
                    print("‚ö†Ô∏è Valor inv√°lido para janela")
                except Exception as e:
                    logger.error(f"‚ùå Erro na an√°lise: {e}")
                    print(f"‚ùå Erro: {e}")
            
            elif opcao == "5":
                print("üìà Executando an√°lise de frequ√™ncia temporal...")
                try:
                    janela = int(input("Tamanho das janelas (padr√£o 15): ") or 15)
                    df_freq = predictor.pattern_analyzer.analisar_frequencia_temporal(janela)
                    
                    print("\nüìà N√öMEROS EM ALTA:")
                    altas = df_freq[df_freq['tendencia'].isin(['üî• Forte alta', '‚¨ÜÔ∏è Alta'])]
                    if not altas.empty:
                        print(altas[['numero', 'diferenca', 'tendencia']].to_string(index=False))
                    else:
                        print("Nenhum n√∫mero em alta significativa")
                    
                    print("\nüìâ N√öMEROS EM BAIXA:")
                    baixas = df_freq[df_freq['tendencia'].isin(['‚ùÑÔ∏è Forte baixa', '‚¨áÔ∏è Baixa'])]
                    if not baixas.empty:
                        print(baixas[['numero', 'diferenca', 'tendencia']].to_string(index=False))
                    else:
                        print("Nenhum n√∫mero em baixa significativa")
                        
                except ValueError:
                    print("‚ö†Ô∏è Valor inv√°lido para janela")
                except Exception as e:
                    logger.error(f"‚ùå Erro na an√°lise: {e}")
                    print(f"‚ùå Erro: {e}")
            
            else:
                print("‚ö†Ô∏è Op√ß√£o inv√°lida")
                
        except KeyboardInterrupt:
            print("\nüëã Opera√ß√£o cancelada pelo usu√°rio")
            break
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado: {e}")
            print(f"‚ùå Erro inesperado: {e}")

if __name__ == "__main__":
    main()
